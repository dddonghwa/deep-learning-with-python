{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "\bch4_02_ml_basic.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMuuF4ho3mh9tvK94CMjD9M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dddonghwa/deep-learning-with-python/blob/main/%08ch4_02_ml_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "FpqnE3s_SATw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.1 네트워크 크기 축소\n",
        "과대적합을 막는 방법 모델에 있는 학습 파라미터 수를 줄이기  \n",
        "딥러닝 모델 = 최적화 + 일반화  \n",
        "적절한 모델의 크기를 찾아야 함"
      ],
      "metadata": {
        "id": "cPr1rlJO_YZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드 4-3 원본 모델\n",
        "\n",
        "from keras import models, layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "2_qy-_Z3NhsO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드 4-4 작은 용량의 모델\n",
        "from keras import models, layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(6, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(6, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "_UMXO0lUOK65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "더 작은 네트워크가 과대적합되기 쉽다"
      ],
      "metadata": {
        "id": "q8FKv9PgOnDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드 4-5 큰 용량의 모델\n",
        "from keras import models, layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(1024, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Desne(1024, activation='relu'))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "cjfrPgcuOq9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "더 큰 네트워크도 과대적합되기 쉽다"
      ],
      "metadata": {
        "id": "NnIqTWNoPCAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.2 가중치 규제 추가\n",
        "가중치 규제(weight regularization)  \n",
        "손실함수에 가중치와 연관된 항을 추가\n",
        "- L1 규제 : 가중치의 절댓값에 비례하는 항 추가\n",
        "- L2 규제 : 가중치의 제곱에 비례하는 항 추가 = 가중치 감쇠(weight decay)"
      ],
      "metadata": {
        "id": "qnM3x_N5PMjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드 4-6 모델에 L2 가중치 추가하기\n",
        "from keras import regularizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
        "                       activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
        "                       activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "YAd0YbySPPQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드 4-7 케라스에서 사용할 수 있는 가중치 규제\n",
        "from keras import regularizers\n",
        "\n",
        "regularizers.l1(0.001) # L1 규제\n",
        "regularizers.l1_l2(l1=0.001, l2=0.001) # L1와 L2 규제"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhP-3zycQ5Ed",
        "outputId": "524a246e-53bf-4ff9-87ca-70f58cb64e68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.regularizers.L1L2 at 0x7f5f7de8c6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.3 드롭아웃 추가\n",
        "무작위로 층의 일부 출력을 0으로 만듬  \n",
        "보통 0.2~0.5, 즉 20~50% 출력을 0으로 만듦  \n",
        "테스트 단계에서는 드롭아웃X 대신 층의 출력을 드롭아웃 비율에 비례하여 줄여줌\n",
        "\n",
        "\n",
        "#### cf. numpy.random.randint(low, high, size=())\n",
        "[low,high) 사이의 정수 값을 동일한 확률로 추출   \n",
        "np.random.randint(0,high=2)의 경우 50:50의 확률로 0, 1 값을 추출\n"
      ],
      "metadata": {
        "id": "vThmiYPsRGAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10; features = 5\n",
        "layer_output = np.random.randn(batch_size, features)\n",
        "layer_output *= np.random.randint(0, high=2, size=layer_output.shape) # 유닛의 출력중 50%를 제거"
      ],
      "metadata": {
        "id": "UHPGyvLpRN5B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_output *= 0.5 # 테스트 단계에서 출력을 반으로 줄임"
      ],
      "metadata": {
        "id": "1sS4yg2NR-Ma"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스에서는 출력층 바로 뒤에 Dropout 층을 추가하여 네트워크에 드롭아웃을 적용"
      ],
      "metadata": {
        "id": "rVcXjXFUScEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드 4-8 IMDB 네트워크에 드롭아웃 추가하기\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "Cl_sx7wrUIeY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####과대 적합을 방지하기 위해선\n",
        "- 훈련 데이터를 더 모은다\n",
        "- 네트워트 용량/크기를 감소시킨다, 파라미터 수를 줄인다\n",
        "- 가중치 규제를 추가\n",
        "- 드롭아웃을 추가"
      ],
      "metadata": {
        "id": "JvQaqku7UhFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.7 모델 규제와 하이퍼파라미터 튜닝\n",
        "좋은 모델을 만들기 위해 적용해 볼 것\n",
        "- 드롭아웃 추가\n",
        "- 층을 추가/제거하여 다른 구조를 시도\n",
        "- L1/L2 또는 두가지 모두 추가\n",
        "- 최적의 설정을 찾기 위해 하이퍼파라미터 뉴튜닝\n",
        "- 특성 공학 시도\n",
        "\n",
        "## 4.6 요약\n",
        "- 주어진 문제와 훈련할 데이터를 정의, 데이터를 수집하고 필요하면 레이블 태깅\n",
        "- 검증 데이터에서 모니터링할 지표?\n",
        "- 평가 방법 : 홀드아웃 검증 / K-겹 교차 검증\n",
        "- 단순한 랜덤 선택 모델보다 나은 통계력 검정력이 있는 첫번째 모델 생성\n",
        "- 과대적합된 모델을 생성\n",
        "- 검증 데이터의 성능에 기초하여 모델에 규젤르 적용하고 하이퍼파라미터 튜닝"
      ],
      "metadata": {
        "id": "7n4u8YcLUxGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PWVyNZAoWZtE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}